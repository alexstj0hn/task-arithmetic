{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexstj0hn/task-arithmetic/blob/main/notebooks/colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSUrQdig37KX"
      },
      "source": [
        "# Protein Task Vectors — Phase 1 Training (Colab)\n",
        "\n",
        "Run on a free T4 GPU. Train one property at a time.\n",
        "\n",
        "**Before starting:** Runtime → Change runtime type → **T4 GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZWkZRfj37KZ"
      },
      "source": [
        "## Step 1: Mount Google Drive (for persistent storage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8qLfJh9x37KZ",
        "outputId": "91fa9010-1d4d-45d5-afef-505595451a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted. Checkpoints will persist between sessions.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create persistent directory on Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/protein-task-vectors/checkpoints\n",
        "!mkdir -p /content/drive/MyDrive/protein-task-vectors/zero_shot\n",
        "!mkdir -p /content/drive/MyDrive/protein-task-vectors/phase1_metrics\n",
        "!mkdir -p /content/drive/MyDrive/protein-task-vectors/task_vectors\n",
        "print('Google Drive mounted. Checkpoints will persist between sessions.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhf82p1z37Ka"
      },
      "source": [
        "## Step 2: Clone repo and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n-6DtHNK37Kb",
        "outputId": "6efd088a-5b20-4b74-883b-1d44734093cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/task-arithmetic'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 55 (delta 3), reused 55 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (55/55), 93.33 KiB | 18.67 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/task-arithmetic\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for protein-property-vectors (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# CHANGE THIS to your GitHub repo URL\n",
        "REPO_URL = \"https://github.com/alexstj0hn/task-arithmetic.git\"\n",
        "\n",
        "import os\n",
        "if os.path.exists('/content/task-arithmetic'):\n",
        "    %cd /content/task-arithmetic\n",
        "    !git pull\n",
        "else:\n",
        "    !git clone {REPO_URL} /content/task-arithmetic\n",
        "    %cd /content/task-arithmetic\n",
        "\n",
        "!pip install -e . -q\n",
        "print('\\nDependencies installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eLS5tcq-37Kb",
        "outputId": "9f4e1662-f3c9-4c8d-ba6c-795089f72172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01683a607f83878e95436632d73e1d7d9ae30955\n"
          ]
        }
      ],
      "source": [
        "# Install MMseqs2\n",
        "!cd /tmp && wget -q https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz && tar xzf mmseqs-linux-avx2.tar.gz && cp mmseqs/bin/mmseqs /usr/local/bin/\n",
        "!mmseqs version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q-Mm6XZi37Kb",
        "outputId": "644a8c59-3d57-4334-e308-81c1c188f166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n",
            "VRAM: 15.6 GB\n",
            "bfloat16: True\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
        "print(f'bfloat16: {torch.cuda.is_bf16_supported()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create merged config with T4-safe settings\n",
        "# (base config assumes A100 80GB; T4 has only 16GB)\n",
        "import yaml\n",
        "\n",
        "with open('configs/train_config.yaml') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "with open('configs/colab_overrides.yaml') as f:\n",
        "    overrides = yaml.safe_load(f)\n",
        "\n",
        "# Deep merge overrides into config\n",
        "for section, values in overrides.items():\n",
        "    if section in config and isinstance(config[section], dict):\n",
        "        config[section].update(values)\n",
        "    else:\n",
        "        config[section] = values\n",
        "\n",
        "# Write merged config\n",
        "with open('configs/train_config_colab.yaml', 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print('Created configs/train_config_colab.yaml with T4-safe settings:')\n",
        "print(f'  mixed_precision: {config[\"training\"][\"mixed_precision\"]}')\n",
        "print(f'  batch_size: {config[\"training\"][\"batch_size\"]}')\n",
        "print(f'  list_size: {config[\"training\"][\"list_size\"]}')\n",
        "print(f'  grad_accum: {config[\"training\"][\"gradient_accumulation_steps\"]}')\n",
        "print(f'  eval_batch_size: {config[\"evaluation\"][\"eval_batch_size\"]}')"
      ],
      "metadata": {
        "id": "ZeL3q_mZ37Kc",
        "outputId": "a698e9eb-8dd0-45c8-bacd-4e7c5215fe4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created configs/train_config_colab.yaml with T4-safe settings:\n",
            "  mixed_precision: fp16\n",
            "  batch_size: 2\n",
            "  list_size: 16\n",
            "  grad_accum: 16\n",
            "  eval_batch_size: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTMcb-nS37Kc"
      },
      "source": [
        "## Step 3: Symlink results to Google Drive\n",
        "\n",
        "This way checkpoints survive Colab disconnects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oi75SBj437Kd",
        "outputId": "2bbebd71-7e44-49c7-f474-d9e4a142007b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  checkpoints: symlinked to Drive\n",
            "  zero_shot: symlinked to Drive\n",
            "  phase1_metrics: symlinked to Drive\n",
            "  task_vectors: symlinked to Drive\n",
            "\n",
            "Results will be saved to Google Drive automatically.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "DRIVE_DIR = '/content/drive/MyDrive/protein-task-vectors'\n",
        "REPO_DIR = '/content/task-arithmetic'\n",
        "\n",
        "os.makedirs(os.path.join(REPO_DIR, 'results'), exist_ok=True)\n",
        "\n",
        "# Symlink results subdirs to Google Drive\n",
        "for subdir in ['checkpoints', 'zero_shot', 'phase1_metrics', 'task_vectors']:\n",
        "    local = os.path.join(REPO_DIR, 'results', subdir)\n",
        "    remote = os.path.join(DRIVE_DIR, subdir)\n",
        "    if os.path.islink(local):\n",
        "        print(f'  {subdir}: already symlinked')\n",
        "    else:\n",
        "        if os.path.isdir(local):\n",
        "            # Copy any existing files first\n",
        "            for f in os.listdir(local):\n",
        "                src = os.path.join(local, f)\n",
        "                dst = os.path.join(remote, f)\n",
        "                if not os.path.exists(dst):\n",
        "                    shutil.copy2(src, dst) if os.path.isfile(src) else shutil.copytree(src, dst)\n",
        "            shutil.rmtree(local)\n",
        "        os.symlink(remote, local)\n",
        "        print(f'  {subdir}: symlinked to Drive')\n",
        "\n",
        "print('\\nResults will be saved to Google Drive automatically.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO2zSLcX37Kd"
      },
      "source": [
        "## Step 4: Download data\n",
        "\n",
        "Downloads ProteinGym (~500MB). Only runs once — skips if already downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uXkAjhr037Kd",
        "outputId": "30526dfe-2600-47d7-a9f4-6bc7dead4d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading reference file from https://raw.githubusercontent.com/OATML-Markslab/ProteinGym/main/reference_files/DMS_substitutions.csv\n",
            "Reference CSV: 213kB [00:00, 710kB/s]                 \n",
            "Downloaded to: data/raw/DMS_substitutions.csv\n",
            "\n",
            "Downloading DMS assays from https://marks.hms.harvard.edu/proteingym/ProteinGym_v1.3/DMS_ProteinGym_substitutions.zip\n",
            "This may take a few minutes (~500MB)...\n",
            "DMS Assays ZIP: 43.0MB [00:04, 8.78MB/s]                \n",
            "Downloaded to: data/raw/DMS_ProteinGym_substitutions.zip\n",
            "\n",
            "Extracting ZIP to data/raw/DMS_ProteinGym_substitutions...\n",
            "Removed ZIP file: data/raw/DMS_ProteinGym_substitutions.zip\n",
            "\n",
            "Validating download...\n",
            "✓ Validation successful!\n",
            "  Found 217 / 217 assay files\n",
            "\n",
            "✓ Download complete. Data saved to: data/raw\n"
          ]
        }
      ],
      "source": [
        "!python -m src.data.download --config configs/train_config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3kjEx937Kd"
      },
      "source": [
        "## Step 5: Categorize and split (if not already done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3yu2wxkK37Ke",
        "outputId": "8e4d4838-0aa1-4472-871e-e6960d007e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already categorized.\n",
            "Splits already created.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('data/processed/category_assignments.json'):\n",
        "    !python -m src.data.categorize --config configs/train_config.yaml\n",
        "else:\n",
        "    print('Already categorized.')\n",
        "\n",
        "if not os.path.exists('data/splits/train_assays.json'):\n",
        "    !python -m src.data.splits --config configs/train_config.yaml\n",
        "else:\n",
        "    print('Splits already created.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxop_kly37Ke"
      },
      "source": [
        "## Step 6: Zero-shot baseline\n",
        "\n",
        "Scores all assays with ESM-2 masked marginal likelihood.\n",
        "This takes ~2-4 hours for all 217 assays on T4. Skips already-scored assays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lqdiYaF37Ke",
        "outputId": "6b4de4ce-ee4c-4624-b54b-2629680203c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-18 08:35:46,349 [INFO] numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "Loaded reference file: data/raw/DMS_substitutions.csv\n",
            "  Shape: (217, 46)\n",
            "  Columns: ['DMS_index', 'DMS_id', 'DMS_filename', 'UniProt_ID', 'taxon', 'source_organism', 'target_seq', 'seq_len', 'includes_multiple_mutants', 'DMS_total_number_mutants']...\n",
            "2026-02-18 08:35:46,546 [INFO] __main__: Scoring 217 assays...\n",
            "2026-02-18 08:35:59,264 [INFO] __main__: Loading facebook/esm2_t33_650M_UR50D...\n",
            "2026-02-18 08:35:59,562 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-18 08:35:59,567 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:35:59,574 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/config.json \"HTTP/1.1 200 OK\"\n",
            "config.json: 100% 724/724 [00:00<00:00, 4.49MB/s]\n",
            "2026-02-18 08:35:59,800 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-18 08:36:00,038 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-18 08:36:00,044 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:36:00,276 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "2026-02-18 08:36:00,276 [WARNING] huggingface_hub.utils._http: Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "2026-02-18 08:36:00,543 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/facebook/esm2_t33_650M_UR50D/xet-read-token/08e4846e537177426273712802403f7ba8261b6c \"HTTP/1.1 200 OK\"\n",
            "model.safetensors: 100% 2.61G/2.61G [00:14<00:00, 180MB/s]\n",
            "Loading weights: 100% 571/571 [00:00<00:00, 849.37it/s, Materializing param=lm_head.layer_norm.weight]\n",
            "\u001b[1mEsmForMaskedLM LOAD REPORT\u001b[0m from: facebook/esm2_t33_650M_UR50D\n",
            "Key                         | Status     |  | \n",
            "----------------------------+------------+--+-\n",
            "esm.embeddings.position_ids | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "2026-02-18 08:36:16,500 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-18 08:36:16,506 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:36:16,512 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "tokenizer_config.json: 100% 95.0/95.0 [00:00<00:00, 671kB/s]\n",
            "2026-02-18 08:36:16,741 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/facebook/esm2_t33_650M_UR50D/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-18 08:36:16,968 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/facebook/esm2_t33_650M_UR50D/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:36:17,195 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/vocab.txt \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-18 08:36:17,200 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/vocab.txt \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:36:17,207 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/vocab.txt \"HTTP/1.1 200 OK\"\n",
            "vocab.txt: 100% 93.0/93.0 [00:00<00:00, 670kB/s]\n",
            "2026-02-18 08:36:17,441 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-18 08:36:17,669 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/special_tokens_map.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-18 08:36:17,674 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-18 08:36:17,680 [INFO] httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/facebook/esm2_t33_650M_UR50D/08e4846e537177426273712802403f7ba8261b6c/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 915kB/s]\n",
            "2026-02-18 08:36:17,904 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/tokenizer.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-18 08:36:18,133 [INFO] httpx: HTTP Request: HEAD https://huggingface.co/facebook/esm2_t33_650M_UR50D/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-18 08:36:22,145 [INFO] __main__: Model loaded on cuda\n",
            "2026-02-18 08:36:22,151 [INFO] __main__: \n",
            "A0A140D2T1_ZIKV_Sourisseau_2019:\n",
            "Scoring variants:   0% 13/9576 [00:24<4:57:23,  1.87s/it]"
          ]
        }
      ],
      "source": [
        "!python scripts/04_zero_shot.py --config configs/train_config_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9u39Jwz37Ke"
      },
      "source": [
        "## Step 7: Train property models\n",
        "\n",
        "Train ONE property per Colab session.\n",
        "Change `PROPERTY` below and run a new session for each.\n",
        "\n",
        "Order: stability → binding → expression → activity\n",
        "\n",
        "Each takes ~2-4 hours on T4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TlXsexw37Ke"
      },
      "outputs": [],
      "source": [
        "#########################################\n",
        "# CHANGE THIS for each training session #\n",
        "#########################################\n",
        "PROPERTY = \"stability\"  # stability | binding | expression | activity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc1WjsJv37Ke"
      },
      "outputs": [],
      "source": [
        "!python scripts/05_train_property_models.py \\\n",
        "    --config configs/train_config_colab.yaml \\\n",
        "    --property {PROPERTY} \\\n",
        "    --resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YplIvN9_37Ke"
      },
      "source": [
        "## Step 8: Evaluate (after all 4 properties are trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWWZ6tU137Ke"
      },
      "outputs": [],
      "source": [
        "# Per-property evaluation\n",
        "for prop in ['stability', 'binding', 'expression', 'activity']:\n",
        "    print(f'\\n=== Evaluating {prop} ===')\n",
        "    !python scripts/06_evaluate.py --config configs/train_config_colab.yaml --property {prop}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfZgvTen37Ke"
      },
      "outputs": [],
      "source": [
        "# Cross-property matrix (THE key result)\n",
        "!python scripts/06_evaluate.py --config configs/train_config_colab.yaml --cross-property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCj55OIB37Ke"
      },
      "outputs": [],
      "source": [
        "# View the result\n",
        "import pandas as pd\n",
        "matrix = pd.read_csv('results/phase1_metrics/cross_property_matrix.csv', index_col=0)\n",
        "print('Cross-Property Evaluation Matrix (Spearman correlation)')\n",
        "print(matrix.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeSrKao737Kf"
      },
      "source": [
        "## Step 9: Extract task vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_joq4mHL37Kf"
      },
      "outputs": [],
      "source": [
        "!python scripts/07_extract_vectors.py --config configs/train_config_colab.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiqFNAEk37Kf"
      },
      "outputs": [],
      "source": [
        "# View cosine similarity between task vectors\n",
        "import pandas as pd\n",
        "sim = pd.read_csv('results/task_vectors/cosine_similarity_matrix.csv', index_col=0)\n",
        "print('Task Vector Cosine Similarity')\n",
        "print(sim.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHBD7ACH37Kf"
      },
      "source": [
        "## Done!\n",
        "\n",
        "All results are saved to your Google Drive at:\n",
        "- `My Drive/protein-task-vectors/checkpoints/` — trained models\n",
        "- `My Drive/protein-task-vectors/phase1_metrics/` — evaluation results\n",
        "- `My Drive/protein-task-vectors/task_vectors/` — extracted vectors\n",
        "\n",
        "You can close this notebook. Everything persists on Drive."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}